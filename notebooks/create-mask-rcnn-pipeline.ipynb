{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version: 1.42.0\n",
      "Tensorflow Version: 2.5.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "from azureml.core import Environment, VERSION, Workspace, Experiment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import Pipeline, StepSequence\n",
    "\n",
    "print(f\"Azure ML SDK Version: {VERSION}\")\n",
    "print(f\"Tensorflow Version: {tf.version.VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the actual ML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_NAME = \"UNIMIB2016-label_20220827_100542\"\n",
    "COMPUTE_NAME = \"ML-Workspa-com1\"\n",
    "PIPELINE_NAME = \"food-segmentation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_ml_workspace = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_rcnn_experiment = Experiment(workspace=azure_ml_workspace, name=\"food-segmentation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": \"FROM tensorflow/tensorflow:2.5.0-gpu\\n\\n# Fix for the public key error\\n# https://github.com/NVIDIA/nvidia-docker/issues/1632\\nRUN apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/3bf863cc.pub\\nRUN apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/7fa2af80.pub\\n\\n\\n# Install Common Dependencies\\nRUN apt-get update && \\\\\\n    apt-get install -y --no-install-recommends \\\\\\n    wget \\\\\\n    ffmpeg \\\\\\n    libsm6 \\\\\\n    libxext6\\n\\n# Conda Environment\\nENV MINICONDA_VERSION py38_4.11.0\\nENV PATH /opt/miniconda/bin:$PATH\\nRUN wget -qO /tmp/miniconda.sh https://repo.anaconda.com/miniconda/Miniconda3-${MINICONDA_VERSION}-Linux-x86_64.sh && \\\\\\n    bash /tmp/miniconda.sh -bf -p /opt/miniconda && \\\\\\n    conda clean -ay && \\\\\\n    rm -rf /opt/miniconda/pkgs && \\\\\\n    rm /tmp/miniconda.sh && \\\\\\n    find / -type d -name __pycache__ | xargs rm -rf\",\n",
       "        \"baseImage\": null,\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": null,\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {\n",
       "        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n",
       "    },\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"food-segmentation\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"anaconda\",\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.8.12\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults==1.42.0\",\n",
       "                        \"azureml-pipeline==1.42.0\",\n",
       "                        \"numpy>=1.10,<1.20\",\n",
       "                        \"pandas>=1.1,<1.2\",\n",
       "                        \"scipy>=1.5,<1.6\",\n",
       "                        \"Pillow\",\n",
       "                        \"cython\",\n",
       "                        \"matplotlib>=3.3,<3.4\",\n",
       "                        \"scikit-image\",\n",
       "                        \"tensorflow~=2.5.0\",\n",
       "                        \"opencv-python==4.5.5.64\",\n",
       "                        \"opencv-python-headless==4.5.5.64\",\n",
       "                        \"h5py\",\n",
       "                        \"imgaug\",\n",
       "                        \"IPython\",\n",
       "                        \"timm==0.4.5\",\n",
       "                        \"seaborn==0.11.2\"\n",
       "                    ]\n",
       "                },\n",
       "                \"pip\"\n",
       "            ],\n",
       "            \"name\": \"project_environment\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": \"python\",\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"3\"\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_env = Environment.from_dockerfile(\"food-segmentation\", \n",
    "                                            dockerfile=\"../pipeline/Dockerfile\",\n",
    "                                            pip_requirements=\"../pipeline/requirements.txt\")\n",
    "\n",
    "pipeline_env.register(workspace=azure_ml_workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the compute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target_cc = azure_ml_workspace.compute_targets[COMPUTE_NAME]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create run configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_run_config = RunConfiguration()\n",
    "train_run_config.environment = Environment.get(workspace=azure_ml_workspace, name=pipeline_env.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_folder = \"download\"\n",
    "train_arguments = [\n",
    "    \"--dataset_name\", DATASET_NAME,\n",
    "    \"--download_folder\", download_folder,\n",
    "    \"--epochs\", 50\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_script_step = PythonScriptStep(\n",
    "    name=\"Train Mask R-CNN\",\n",
    "    source_directory=\"./..\",\n",
    "    script_name=\"train.py\",\n",
    "    arguments=train_arguments,\n",
    "    compute_target=compute_target_cc,\n",
    "    allow_reuse=False,\n",
    "    runconfig=train_run_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_sequence = StepSequence(steps=[\n",
    "    train_script_step\n",
    "])\n",
    "\n",
    "mask_rcnn_pipeline = Pipeline(\n",
    "    workspace=azure_ml_workspace,\n",
    "    steps=[step_sequence]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Train Mask R-CNN [4e15873f][679fb522-87c5-42ce-96b1-3b5859152462], (This step will run and generate new outputs)\n"
     ]
    }
   ],
   "source": [
    "published_pipeline = mask_rcnn_pipeline.publish(PIPELINE_NAME, version=\"0.0.1\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "ovencam-volume-estimation"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('calorie-estimation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "toc-autonumbering": false,
  "vscode": {
   "interpreter": {
    "hash": "bebe33104f02cc1e84e7a6d138a5dffd075e4f579c418e28080f58e1f1fdc086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
